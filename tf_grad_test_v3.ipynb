{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0142884\n",
      "0.0271016\n"
     ]
    }
   ],
   "source": [
    "knn__ = 12\n",
    "batch_size__ = 32\n",
    "\n",
    "uniforms_ = []\n",
    "peaks_ = []\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # initialize exponential mass\n",
    "    m_np = np.random.exponential(80., [batch_size__,1])+80.\n",
    "    #m_np = np.array([120.,120.,120.,120.,120.,120.])\n",
    "    #m_np = np.array([100.,150.,140.,130.,125.,110.])\n",
    "    m__ = tf.constant(m_np, dtype=tf.float32)\n",
    "\n",
    "    # init binary class\n",
    "    #y_true_np = np.random.randint(2, size=batch_size__)\n",
    "    y_true_np = np.zeros(batch_size__)\n",
    "    y_true__ = tf.constant(y_true_np, dtype=tf.int32)\n",
    "\n",
    "    # init preds\n",
    "    y_pred_np = np.random.rand(batch_size__,1)\n",
    "    #y_pred_np = np.array([0.6,0.6,0.6,0.6,0.6,0.6])\n",
    "    #y_pred_np = np.array([0.1,0.2,.9,.8,0.5,0.6])\n",
    "    # uniform distribution\n",
    "    y_pred__ = tf.constant(y_pred_np, dtype=tf.float32)\n",
    "    uniforms_.append(cvm_loss_grad(y_pred__, m__, y_true__, knn__, debug=False)[0].eval())\n",
    "    print(uniforms_[-1])\n",
    "    # peaked: artificially set masses near 125 to have y_pred=1.\n",
    "    y_pred_np[(m_np > 115.) & (m_np < 135.)] = 1.\n",
    "    y_pred__ = tf.constant(y_pred_np, dtype=tf.float32)\n",
    "    peaks_.append(cvm_loss_grad(y_pred__, m__, y_true__, knn__, debug=False)[0].eval())\n",
    "    print(peaks_[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_uniform(y_pred, m_i, m, debug=True):\n",
    "    '''\n",
    "    Sample a uniform CDF and order them according to y_pred\n",
    "    '''\n",
    "    # Get kNN of m_i #\n",
    "    dist = tf.abs(tf.subtract(m_i, m))\n",
    "    # Get index i\n",
    "    _, indices_knn = tf.nn.top_k(tf.negative(dist), k=1)\n",
    "    i = indices_knn[0]\n",
    "\n",
    "    # Make a uniform pdf\n",
    "    pdf = tf.ones_like(y_pred)\n",
    "    cdf = tf.cumsum(pdf)\n",
    "    #if debug: print('cdf',cdf.eval())\n",
    "    cdf = tf.divide(cdf, cdf[-1])\n",
    "    \n",
    "    # Sort all y_preds\n",
    "    _, indices_pred_sorted = tf.nn.top_k(tf.negative(y_pred), k=tf.shape(y_pred)[0])\n",
    "    #if debug: print('indices_pred_sorted',indices_pred_sorted.eval())\n",
    "    _, indices_orig = tf.nn.top_k(tf.negative(indices_pred_sorted), k=tf.shape(y_pred)[0])\n",
    "    \n",
    "    # Sample from cdf in same order as scores in y_pred\n",
    "    cdf_pred = tf.gather(cdf, indices_orig)\n",
    "    if debug: print('cdf_pred',cdf_pred.eval(),'i_',i.eval())\n",
    "    \n",
    "    return cdf_pred, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_i: [ 110.97079468]\n",
      "cdf_pred [ 0.4375   0.53125  0.5625   0.125    0.75     0.96875  0.25     0.21875\n",
      "  0.40625  0.65625  0.03125  0.375    0.15625  0.8125   0.34375  0.6875\n",
      "  0.46875  0.90625  0.84375  0.625    0.59375  1.       0.28125  0.09375\n",
      "  0.1875   0.875    0.9375   0.5      0.3125   0.71875  0.0625   0.78125] i_ 4\n",
      "dist [   6.66320038   17.14775848    4.89836121   18.22296143    0.\n",
      "   27.47932434    6.67206573  267.69012451   74.61419678   21.17259216\n",
      "    8.08588409   48.24597168   20.2829895   297.61682129   15.87670898\n",
      "   93.71295166   95.46559143    4.89002228   12.07178497   39.24446106\n",
      "   83.25579834   14.32927704    3.7778244    57.77528381   24.42472839\n",
      "   15.23423767   11.66690063   13.19974518   29.72079468  111.90922546\n",
      "   14.58078766  221.42474365]\n",
      "indices_knn [ 4 22 17  2]\n",
      "y_pred_knn [ 0.73169005  0.25472414  0.97287232  0.51047093]\n",
      "m_knn [ 110.97079468  107.19297028  115.86081696  106.07243347]\n",
      "cdf_pred [ 0.75  0.25  1.    0.5 ] i_ 0\n",
      "loss_i: 0.00341797  grad_i: 0.0\n"
     ]
    }
   ],
   "source": [
    "def cvm_loss_grad_i(y_pred, m_i, m, K, debug=False):\n",
    "    '''\n",
    "    Calculate CVM gradient and loss contribution for the ith sample.\n",
    "    CVM is expressed in terms of the CDF of the kNN(i) prediction scores s, F_knn(i)_(s)\n",
    "    and of a reference uniform CDF, F_(s).\n",
    "    \n",
    "    Args:\n",
    "        y_pred: array of prediction scores (including the ith sample)\n",
    "        m_i: scalar representing mass of the ith sample\n",
    "        m: array of mass values (including the ith sample)\n",
    "        K: scalar representing number of nearest neighbors to use (including the ith sample)\n",
    "    Returns:\n",
    "        loss_i: contribution of the ith sample to the CVM loss\n",
    "        grad_i: CVM gradient wrt y_pred_i\n",
    "    \n",
    "    '''\n",
    "    if debug: print('m_i:',m_i.eval())\n",
    "    \n",
    "    y_pred = tf.squeeze(y_pred)\n",
    "    m = tf.squeeze(m)\n",
    "    \n",
    "    # Sample CDF like y_pred\n",
    "    cdf_pred_all, i_all = sample_uniform(y_pred, m_i, m, debug)\n",
    "    \n",
    "    # Get kNN of m_i #\n",
    "    dist = tf.abs(tf.subtract(m_i, m))\n",
    "    if debug: print('dist',dist.eval())\n",
    "    # Sort by distance (i.e. by nearest neighbor)\n",
    "    _, indices_knn = tf.nn.top_k(tf.negative(dist), k=K)\n",
    "    if debug: print('indices_knn',indices_knn.eval())\n",
    "    # Get corresponding y_preds and m for these kNN\n",
    "    y_pred_knn = tf.gather(y_pred, indices_knn)\n",
    "    if debug: print('y_pred_knn',y_pred_knn.eval())\n",
    "    m_knn = tf.gather(m, indices_knn)\n",
    "    if debug: print('m_knn',m_knn.eval())\n",
    "    # Sample CDF like y_pred_knn\n",
    "    cdf_pred_knn, i_knn = sample_uniform(y_pred_knn, m_i, m_knn, debug)\n",
    "    \n",
    "    # Get loss\n",
    "    cdf_pred_all_knn = tf.gather(cdf_pred_all, indices_knn)\n",
    "    integrand = tf.pow(tf.subtract(cdf_pred_knn, cdf_pred_all_knn),2.)\n",
    "    loss_i = tf.reduce_mean(integrand)\n",
    "    \n",
    "    # Get grad\n",
    "    grad_i = tf.abs(tf.subtract(cdf_pred_all[i_all],cdf_pred_knn[i_knn]))\n",
    "    \n",
    "    return tf.stack([loss_i, grad_i])\n",
    "\n",
    "# Debug with smaller K\n",
    "cvm_i = cvm_loss_grad_i(y_pred__, m__[4], m__, 4, debug=True)\n",
    "print('loss_i:',cvm_i[0].eval(),' grad_i:',cvm_i[1].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [[ 0.42541465]\n",
      " [ 0.50400704]\n",
      " [ 0.51047093]\n",
      " [ 0.01579145]\n",
      " [ 0.73169005]\n",
      " [ 0.99330503]\n",
      " [ 0.16287753]\n",
      " [ 0.12663478]\n",
      " [ 0.37483418]\n",
      " [ 0.69321942]\n",
      " [ 0.00290103]\n",
      " [ 0.36922905]\n",
      " [ 0.05867933]\n",
      " [ 0.78933609]\n",
      " [ 0.3497692 ]\n",
      " [ 0.70252371]\n",
      " [ 0.49122909]\n",
      " [ 0.97287232]\n",
      " [ 0.8359679 ]\n",
      " [ 0.61023736]\n",
      " [ 0.56451899]\n",
      " [ 0.99738914]\n",
      " [ 0.25472414]\n",
      " [ 0.01437786]\n",
      " [ 0.08904507]\n",
      " [ 0.93898261]\n",
      " [ 0.97345942]\n",
      " [ 0.49148154]\n",
      " [ 0.34093598]\n",
      " [ 0.72285759]\n",
      " [ 0.01089676]\n",
      " [ 0.7599532 ]]\n",
      "m: [[ 104.3075943 ]\n",
      " [  93.82303619]\n",
      " [ 106.07243347]\n",
      " [ 129.1937561 ]\n",
      " [ 110.97079468]\n",
      " [ 138.45011902]\n",
      " [ 104.29872894]\n",
      " [ 378.66091919]\n",
      " [ 185.58499146]\n",
      " [  89.79820251]\n",
      " [ 119.05667877]\n",
      " [ 159.21676636]\n",
      " [  90.68780518]\n",
      " [ 408.58761597]\n",
      " [ 126.84750366]\n",
      " [ 204.68374634]\n",
      " [ 206.43638611]\n",
      " [ 115.86081696]\n",
      " [ 123.04257965]\n",
      " [ 150.21525574]\n",
      " [ 194.22659302]\n",
      " [  96.64151764]\n",
      " [ 107.19297028]\n",
      " [ 168.74607849]\n",
      " [ 135.39552307]\n",
      " [  95.73655701]\n",
      " [ 122.63769531]\n",
      " [  97.7710495 ]\n",
      " [ 140.69158936]\n",
      " [ 222.88002014]\n",
      " [  96.39000702]\n",
      " [ 332.39553833]]\n",
      "net loss: 0.00596647\n",
      "grad wrt y_pred[is_bkg]: [ 0.02083334  0.05208331  0.10416669  0.04166667  0.08333331  0.03125     0.\n",
      "  0.05208333  0.09375     0.09375     0.05208334  0.125       0.01041667\n",
      "  0.1875      0.15625     0.14583331  0.11458331  0.01041669  0.09375\n",
      "  0.04166669  0.07291669  0.          0.05208334  0.01041666  0.0625\n",
      "  0.04166669  0.02083331  0.          0.10416666  0.19791669  0.02083334\n",
      "  0.13541669]\n"
     ]
    }
   ],
   "source": [
    "def cvm_loss_grad(y_pred_, m_, y_true, K, debug=False):\n",
    "    '''\n",
    "    Calculate Cramer-von Mises loss and gradient (with kNN modification) for this batch.\n",
    "    See: https://arxiv.org/pdf/1410.4140.pdf\n",
    "    '''   \n",
    "    # Only pick out bkg events (i.e. label=0)\n",
    "    is_bkg = tf.equal(tf.cast(y_true, dtype=tf.int32), 0)\n",
    "    y_pred = tf.boolean_mask(y_pred_, is_bkg)\n",
    "    if debug: print('y_pred:',y_pred.eval())\n",
    "    m = tf.boolean_mask(m_, is_bkg)\n",
    "    if debug: print('m:',m.eval())\n",
    "    \n",
    "    cvm = tf.map_fn(lambda m_i: cvm_loss_grad_i(y_pred, m_i, m, K, debug=False), m, dtype=tf.float32)\n",
    "    loss = tf.reduce_mean(cvm[:,0]) # assume each loss_i is equally weighted\n",
    "    grad = cvm[:,1]\n",
    "    \n",
    "    #TODO: return grad for label=1 elements in y_pred as well (i.e. None)\n",
    "    #grads = tf.zeros_like(y_pred_)\n",
    "    #grads[is_bkg] = cvm[:,1]\n",
    "    \n",
    "    return loss, grad\n",
    "    \n",
    "# Debug\n",
    "cvm = cvm_loss_grad(y_pred__, m__, y_true__, knn__, debug=True)\n",
    "print('net loss:',cvm[0].eval())\n",
    "print('grad wrt y_pred[is_bkg]:',cvm[1].eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
