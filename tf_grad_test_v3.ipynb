{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0272856\n",
      "0.0647759\n"
     ]
    }
   ],
   "source": [
    "knn__ = 12\n",
    "batch_size__ = 32\n",
    "\n",
    "uniforms_ = []\n",
    "peaks_ = []\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # initialize exponential mass\n",
    "    m_np = np.random.exponential(80., [batch_size__,1])+80.\n",
    "    #m_np = np.array([120.,120.,120.,120.,120.,120.])\n",
    "    #m_np = np.array([100.,150.,140.,130.,125.,110.])\n",
    "    m__ = tf.constant(m_np, dtype=tf.float32)\n",
    "\n",
    "    # init binary class\n",
    "    #y_true_np = np.random.randint(2, size=batch_size__)\n",
    "    y_true_np = np.zeros(batch_size__)\n",
    "    y_true__ = tf.constant(y_true_np, dtype=tf.int32)\n",
    "\n",
    "    # init preds\n",
    "    y_pred_np = np.random.rand(batch_size__,1)\n",
    "    #y_pred_np = np.array([0.6,0.6,0.6,0.6,0.6,0.6])\n",
    "    #y_pred_np = np.array([0.1,0.2,.9,.8,0.5,0.6])\n",
    "    # uniform distribution\n",
    "    y_pred__ = tf.constant(y_pred_np, dtype=tf.float32)\n",
    "    uniforms_.append(cvm_loss_grad(m__, y_pred__, y_true__, knn__, debug=False)[0].eval())\n",
    "    print(uniforms_[-1])\n",
    "    # peaked: artificially set masses near 125 to have y_pred=1.\n",
    "    y_pred_np[(m_np > 115.) & (m_np < 135.)] = 1.\n",
    "    y_pred__ = tf.constant(y_pred_np, dtype=tf.float32)\n",
    "    peaks_.append(cvm_loss_grad(m__, y_pred__, y_true__, knn__, debug=False)[0].eval())\n",
    "    print(peaks_[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_i: [ 110.97079468]\n",
      "dist [   6.66320038   17.14775848    4.89836121   18.22296143    0.\n",
      "   27.47932434    6.67206573  267.69012451   74.61419678   21.17259216\n",
      "    8.08588409   48.24597168   20.2829895   297.61682129   15.87670898\n",
      "   93.71295166   95.46559143    4.89002228   12.07178497   39.24446106\n",
      "   83.25579834   14.32927704    3.7778244    57.77528381   24.42472839\n",
      "   15.23423767   11.66690063   13.19974518   29.72079468  111.90922546\n",
      "   14.58078766  221.42474365]\n",
      "idx: 4\n",
      "y_pred_knn [ 0.73169005  0.25472414  0.97287232  0.51047093]\n",
      "y_pred_knn_pred_sorted [ 0.25472414  0.51047093  0.73169005  0.97287232] idxs_knn_pred_sorted: [1 3 0 2]\n",
      "j: 2\n",
      "cdf_y_pred_knn [ 0.10313731  0.30982602  0.6060859   1.        ]\n",
      "cdf_y_pred_knn_i: 0.606086\n",
      "integrand [ 0.02297857  0.04025838  0.0157764   0.00073591]\n",
      "0.0199373\n",
      "loss_i: 0.0199373  grad_i: -0.251208\n"
     ]
    }
   ],
   "source": [
    "def cvm_loss_grad_i(m_i, y_pred, m, K, debug=False):\n",
    "    '''\n",
    "    Calculate CVM gradient and loss contribution for the ith sample.\n",
    "    CVM is expressed in terms of the CDF of the kNN(i) prediction scores s, F_knn(i)_(s)\n",
    "    and of a reference uniform CDF, F_(s).\n",
    "    \n",
    "    Args:\n",
    "        m_i: scalar representing mass of the ith sample\n",
    "        y_pred: array of prediction scores (including the ith sample)\n",
    "        m: array of mass values (including the ith sample)\n",
    "        K: scalar representing number of nearest neighbors to use (including the ith sample)\n",
    "    Returns:\n",
    "        loss_i: contribution of the ith sample to the CVM loss\n",
    "        grad_i: CVM gradient wrt y_pred_i\n",
    "    \n",
    "    '''\n",
    "    if debug: print('m_i:',m_i.eval())\n",
    "    \n",
    "    # Get distances |m_i - m|\n",
    "    dist = tf.abs(tf.subtract(m_i, tf.squeeze(m)))\n",
    "    if debug: print('dist',dist.eval())\n",
    "    \n",
    "    # Get kNN of m_i:\n",
    "    # Sort distances by size and get first K elements\n",
    "    _, indices_knn = tf.nn.top_k(tf.negative(dist), k=K)\n",
    "    #_, indices_knn = tf.nn.top_k(tf.reshape(tf.negative(dist), [1,-1]), k=K)\n",
    "    # Then, indices_knn[0] gives position of index i in y_pred\n",
    "    i = tf.squeeze(indices_knn)[0]\n",
    "    if debug: print('idx:',i.eval())\n",
    "    \n",
    "    # Extract elements in y_pred corresponding to kNN\n",
    "    y_pred_knn_dist_sorted = tf.gather(tf.squeeze(y_pred), indices_knn) # these are arranged by increasing distance\n",
    "    # The 0th element corresponds to y_pred_i\n",
    "    y_pred_i = y_pred_knn_dist_sorted[0]\n",
    "    if debug: print('y_pred_knn',y_pred_knn_dist_sorted.eval())\n",
    "    # Arrange them by increasing prediction score\n",
    "    y_pred_knn_pred_sorted, idxs_knn_pred_sorted = tf.nn.top_k(tf.negative(y_pred_knn_dist_sorted), k=K)\n",
    "    y_pred_knn_pred_sorted = tf.abs(y_pred_knn_pred_sorted)\n",
    "    if debug: print('y_pred_knn_pred_sorted',y_pred_knn_pred_sorted.eval(),'idxs_knn_pred_sorted:',idxs_knn_pred_sorted.eval())\n",
    "    # Then, argmin(idxs_knn_pred_sorted) (i.e. position of index 0) \n",
    "    # will correspond to position of index i in y_pred_knn_pred_sorted\n",
    "    j = tf.argmin(idxs_knn_pred_sorted)\n",
    "    if debug: print('j:',j.eval())\n",
    "    \n",
    "    # Get CDF of kNN(i): F_knn(i)_(s)\n",
    "    cdf_y_pred_knn = tf.cumsum(y_pred_knn_pred_sorted)\n",
    "    # Normalize\n",
    "    cdf_y_pred_knn = tf.divide(cdf_y_pred_knn, cdf_y_pred_knn[-1])\n",
    "    if debug: print('cdf_y_pred_knn',cdf_y_pred_knn.eval())\n",
    "    # Get value at s=s_k, F_knn(i)_(s_k) using j from above:\n",
    "    cdf_y_pred_knn_i = cdf_y_pred_knn[j]\n",
    "    if debug: print('cdf_y_pred_knn_i:',cdf_y_pred_knn_i.eval())\n",
    "    \n",
    "    # Get CDF of corresponding uniform distn: F_(s)\n",
    "    # Note: for uniform CDF, F_(s) = s (for increasing s)\n",
    "    cdf_uniform = y_pred_knn_pred_sorted\n",
    "    cdf_uniform_i = y_pred_i\n",
    "    \n",
    "    # Get grad_i: should be exact\n",
    "    # NOTE: this expression from the paper seems to be dimensionally incorrect\n",
    "    # If missing square, this expression would tend to dilute effect of deviant elements.\n",
    "    grad_i = tf.multiply(2.,tf.subtract(cdf_y_pred_knn_i, cdf_uniform_i)) # TODO: determine correct sign and expression\n",
    "    \n",
    "    # Get loss_i: approximate since requires discrete integration over s = y_pred\n",
    "    '''\n",
    "    # Scheme 1:\n",
    "    if debug: print(y_pred_knn_pred_sorted.eval())\n",
    "    s_lo_edge = y_pred_knn_pred_sorted\n",
    "    if debug: print('s_lo_edge',s_lo_edge.eval())\n",
    "    s_hi_edge = tf.concat([tf.slice(y_pred_knn_pred_sorted, begin=[1], size=[K-1]),[1.]], axis=0)\n",
    "    if debug: print('s_hi_edge',s_hi_edge.eval())\n",
    "    ds = s_hi_edge - s_lo_edge\n",
    "    if debug: print('ds',ds.eval())\n",
    "    cdf_uniform_ = tf.reduce_mean(tf.stack([s_lo_edge, s_hi_edge]), axis=0)\n",
    "    if debug: print(cdf_uniform_.eval())\n",
    "    integrand = tf.pow(tf.subtract(cdf_y_pred_knn, cdf_uniform_),2.)\n",
    "    if debug: print('integrand',integrand.eval())\n",
    "    loss_i = tf.reduce_sum(tf.multiply(integrand, ds))\n",
    "    if debug: print(loss_i.eval())\n",
    "    '''\n",
    "    # Scheme 2: \n",
    "    # Will have little effect if y_preds are uniformly dist'd but, in general,\n",
    "    # will under-represent sparsely dist'd scores and over-represent densely dist'd scores\n",
    "    integrand = tf.pow(tf.subtract(cdf_y_pred_knn, cdf_uniform),2.)\n",
    "    if debug: print('integrand',integrand.eval())\n",
    "    loss_i = tf.reduce_mean(integrand)\n",
    "    if debug: print(loss_i.eval())\n",
    "    \n",
    "    return tf.stack([loss_i, grad_i])\n",
    "\n",
    "# Debug with smaller K\n",
    "cvm_i = cvm_loss_grad_i(m__[4], y_pred__, m__, 4, debug=True)\n",
    "print('loss_i:',cvm_i[0].eval(),' grad_i:',cvm_i[1].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [[ 0.42541465]\n",
      " [ 0.50400704]\n",
      " [ 0.51047093]\n",
      " [ 0.01579145]\n",
      " [ 0.73169005]\n",
      " [ 0.99330503]\n",
      " [ 0.16287753]\n",
      " [ 0.12663478]\n",
      " [ 0.37483418]\n",
      " [ 0.69321942]\n",
      " [ 0.00290103]\n",
      " [ 0.36922905]\n",
      " [ 0.05867933]\n",
      " [ 0.78933609]\n",
      " [ 0.3497692 ]\n",
      " [ 0.70252371]\n",
      " [ 0.49122909]\n",
      " [ 0.97287232]\n",
      " [ 0.8359679 ]\n",
      " [ 0.61023736]\n",
      " [ 0.56451899]\n",
      " [ 0.99738914]\n",
      " [ 0.25472414]\n",
      " [ 0.01437786]\n",
      " [ 0.08904507]\n",
      " [ 0.93898261]\n",
      " [ 0.97345942]\n",
      " [ 0.49148154]\n",
      " [ 0.34093598]\n",
      " [ 0.72285759]\n",
      " [ 0.01089676]\n",
      " [ 0.7599532 ]]\n",
      "m: [[ 104.3075943 ]\n",
      " [  93.82303619]\n",
      " [ 106.07243347]\n",
      " [ 129.1937561 ]\n",
      " [ 110.97079468]\n",
      " [ 138.45011902]\n",
      " [ 104.29872894]\n",
      " [ 378.66091919]\n",
      " [ 185.58499146]\n",
      " [  89.79820251]\n",
      " [ 119.05667877]\n",
      " [ 159.21676636]\n",
      " [  90.68780518]\n",
      " [ 408.58761597]\n",
      " [ 126.84750366]\n",
      " [ 204.68374634]\n",
      " [ 206.43638611]\n",
      " [ 115.86081696]\n",
      " [ 123.04257965]\n",
      " [ 150.21525574]\n",
      " [ 194.22659302]\n",
      " [  96.64151764]\n",
      " [ 107.19297028]\n",
      " [ 168.74607849]\n",
      " [ 135.39552307]\n",
      " [  95.73655701]\n",
      " [ 122.63769531]\n",
      " [  97.7710495 ]\n",
      " [ 140.69158936]\n",
      " [ 222.88002014]\n",
      " [  96.39000702]\n",
      " [ 332.39553833]]\n",
      "net loss: 0.0286032\n",
      "grad wrt y_pred[is_bkg]: [-0.54961812 -0.34775937 -0.23383707 -0.02552444 -0.65006852  0.01338995\n",
      " -0.24903119 -0.20519707 -0.29429317 -0.30967033 -0.00471247 -0.31211635\n",
      " -0.09328319  0.42132783 -0.35258451 -0.05401695 -0.34132397 -0.2856741\n",
      " -0.64036584 -0.57668096 -0.2744301   0.00522172 -0.36573726 -0.02290606\n",
      " -0.14380723 -0.22309256 -0.27415204 -0.49711034 -0.51554281  0.17866492\n",
      " -0.01802291  0.21100175]\n"
     ]
    }
   ],
   "source": [
    "def cvm_loss_grad(m_, y_pred_, y_true, K, debug=False):\n",
    "    '''\n",
    "    Calculate Cramer-von Mises loss and gradient (with kNN modification) for this batch.\n",
    "    See: https://arxiv.org/pdf/1410.4140.pdf\n",
    "    '''\n",
    "    \n",
    "    # Only pick out bkg events (i.e. label=0)\n",
    "    is_bkg = tf.equal(tf.cast(y_true, dtype=tf.int32), 0)\n",
    "    y_pred = tf.boolean_mask(y_pred_, is_bkg)\n",
    "    if debug: print('y_pred:',y_pred.eval())\n",
    "    m = tf.boolean_mask(m_, is_bkg)\n",
    "    if debug: print('m:',m.eval())\n",
    "    \n",
    "    cvm = tf.map_fn(lambda m_i: cvm_loss_grad_i(m_i, y_pred, m, K, debug=False), m, dtype=tf.float32)\n",
    "    loss = tf.reduce_mean(cvm[:,0]) # assume each loss_i is equally weighted\n",
    "    grad = cvm[:,1]\n",
    "    \n",
    "    #TODO: return grad for label=1 elements in y_pred as well (i.e. None)\n",
    "    #grads = tf.zeros_like(y_pred_)\n",
    "    #grads[is_bkg] = cvm[:,1]\n",
    "    \n",
    "    return loss, grad\n",
    "    \n",
    "# Debug\n",
    "cvm = cvm_loss_grad(m__, y_pred__, y_true__, knn__, debug=True)\n",
    "print('net loss:',cvm[0].eval())\n",
    "print('grad wrt y_pred[is_bkg]:',cvm[1].eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
